{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem Supervisionada: Regressão e Classificação\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/thomaschiari/ML_AI-Training/blob/main/M2-Modelling/Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/thomaschiari/ML_AI-Training/blob/main/M2-Modelling/Models.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autor:\n",
    "- [Thomas Chiari Ciocchetti de Souza](https://github.com/thomaschiari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos para a modelagem propriamente dita. Neste notebook, vamos abordar os seguintes tópicos:\n",
    "- Processamento de dados utilizando Pipelines\n",
    "- O que é aprendizado supervisionado?\n",
    "- Problemas de regressão e classificação\n",
    "- Principais algoritmos de regressão e avaliação de modelos\n",
    "- Principais algoritmos de classificação e avaliação de modelos\n",
    "- Testes estatísticos e escolha de modelos\n",
    "- Otimização de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processamento de dados utilizando Pipelines\n",
    "\n",
    "O pipeline é uma ferramenta que permite encadear transformações de dados e modelos de aprendizado de máquina. Ele é muito útil para automatizar o processamento de dados e a criação de modelos, além de facilitar a reprodutibilidade dos resultados. É usado para automatizar os fluxos de trabalho e facilitar o processo de modelagem. Aqui, vamos utilizar as Pipelines do `sklearn` para automatizar processamento de dados que foi realizado no notebook do módulo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os dados\n",
    "import os\n",
    "import urllib.request\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/thomaschiari/ML_AI-Training/main/M1-Introduction/data/house-prices/\"\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH = \"test.csv\"\n",
    "TXT_PATH = \"data_description.txt\"\n",
    "TRAIN_URL = DOWNLOAD_ROOT + TRAIN_PATH\n",
    "TEST_URL = DOWNLOAD_ROOT + TEST_PATH\n",
    "TXT_URL = DOWNLOAD_ROOT + TXT_PATH\n",
    "DATA_PATH = os.path.join(\"data\", \"house-prices\")\n",
    "\n",
    "def fetch_data(data_url, data_path):\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    csv_path = os.path.join(data_path, data_url.split('/')[-1])\n",
    "    if not os.path.isfile(csv_path):\n",
    "        urllib.request.urlretrieve(data_url, csv_path)\n",
    "\n",
    "fetch_data(TRAIN_URL, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = os.path.join('data', 'house-prices', 'train.csv')\n",
    "PATH_TEST = os.path.join('data', 'house-prices', 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(PATH_TRAIN, encoding='utf-8')\n",
    "dataset_test = pd.read_csv(PATH_TEST, encoding='utf-8')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>421.610009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.75</td>\n",
       "      <td>730.5</td>\n",
       "      <td>1095.25</td>\n",
       "      <td>1460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1201.0</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>21.0</td>\n",
       "      <td>59.00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>7553.50</td>\n",
       "      <td>9478.5</td>\n",
       "      <td>11601.50</td>\n",
       "      <td>215245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1954.00</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1967.00</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>1452.0</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.00</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>383.5</td>\n",
       "      <td>712.25</td>\n",
       "      <td>5644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.00</td>\n",
       "      <td>477.5</td>\n",
       "      <td>808.00</td>\n",
       "      <td>2336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.75</td>\n",
       "      <td>991.5</td>\n",
       "      <td>1298.25</td>\n",
       "      <td>6110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>334.0</td>\n",
       "      <td>882.00</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>1391.25</td>\n",
       "      <td>4692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>728.00</td>\n",
       "      <td>2065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>5.844521</td>\n",
       "      <td>48.623081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1129.50</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>1776.75</td>\n",
       "      <td>5642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.518911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.382877</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>1379.0</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1961.00</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2002.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.50</td>\n",
       "      <td>480.0</td>\n",
       "      <td>576.00</td>\n",
       "      <td>1418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.00</td>\n",
       "      <td>857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>180921.195890</td>\n",
       "      <td>79442.502883</td>\n",
       "      <td>34900.0</td>\n",
       "      <td>129975.00</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>214000.00</td>\n",
       "      <td>755000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count           mean           std      min        25%  \\\n",
       "Id             1460.0     730.500000    421.610009      1.0     365.75   \n",
       "MSSubClass     1460.0      56.897260     42.300571     20.0      20.00   \n",
       "LotFrontage    1201.0      70.049958     24.284752     21.0      59.00   \n",
       "LotArea        1460.0   10516.828082   9981.264932   1300.0    7553.50   \n",
       "OverallQual    1460.0       6.099315      1.382997      1.0       5.00   \n",
       "OverallCond    1460.0       5.575342      1.112799      1.0       5.00   \n",
       "YearBuilt      1460.0    1971.267808     30.202904   1872.0    1954.00   \n",
       "YearRemodAdd   1460.0    1984.865753     20.645407   1950.0    1967.00   \n",
       "MasVnrArea     1452.0     103.685262    181.066207      0.0       0.00   \n",
       "BsmtFinSF1     1460.0     443.639726    456.098091      0.0       0.00   \n",
       "BsmtFinSF2     1460.0      46.549315    161.319273      0.0       0.00   \n",
       "BsmtUnfSF      1460.0     567.240411    441.866955      0.0     223.00   \n",
       "TotalBsmtSF    1460.0    1057.429452    438.705324      0.0     795.75   \n",
       "1stFlrSF       1460.0    1162.626712    386.587738    334.0     882.00   \n",
       "2ndFlrSF       1460.0     346.992466    436.528436      0.0       0.00   \n",
       "LowQualFinSF   1460.0       5.844521     48.623081      0.0       0.00   \n",
       "GrLivArea      1460.0    1515.463699    525.480383    334.0    1129.50   \n",
       "BsmtFullBath   1460.0       0.425342      0.518911      0.0       0.00   \n",
       "BsmtHalfBath   1460.0       0.057534      0.238753      0.0       0.00   \n",
       "FullBath       1460.0       1.565068      0.550916      0.0       1.00   \n",
       "HalfBath       1460.0       0.382877      0.502885      0.0       0.00   \n",
       "BedroomAbvGr   1460.0       2.866438      0.815778      0.0       2.00   \n",
       "KitchenAbvGr   1460.0       1.046575      0.220338      0.0       1.00   \n",
       "TotRmsAbvGrd   1460.0       6.517808      1.625393      2.0       5.00   \n",
       "Fireplaces     1460.0       0.613014      0.644666      0.0       0.00   \n",
       "GarageYrBlt    1379.0    1978.506164     24.689725   1900.0    1961.00   \n",
       "GarageCars     1460.0       1.767123      0.747315      0.0       1.00   \n",
       "GarageArea     1460.0     472.980137    213.804841      0.0     334.50   \n",
       "WoodDeckSF     1460.0      94.244521    125.338794      0.0       0.00   \n",
       "OpenPorchSF    1460.0      46.660274     66.256028      0.0       0.00   \n",
       "EnclosedPorch  1460.0      21.954110     61.119149      0.0       0.00   \n",
       "3SsnPorch      1460.0       3.409589     29.317331      0.0       0.00   \n",
       "ScreenPorch    1460.0      15.060959     55.757415      0.0       0.00   \n",
       "PoolArea       1460.0       2.758904     40.177307      0.0       0.00   \n",
       "MiscVal        1460.0      43.489041    496.123024      0.0       0.00   \n",
       "MoSold         1460.0       6.321918      2.703626      1.0       5.00   \n",
       "YrSold         1460.0    2007.815753      1.328095   2006.0    2007.00   \n",
       "SalePrice      1460.0  180921.195890  79442.502883  34900.0  129975.00   \n",
       "\n",
       "                    50%        75%       max  \n",
       "Id                730.5    1095.25    1460.0  \n",
       "MSSubClass         50.0      70.00     190.0  \n",
       "LotFrontage        69.0      80.00     313.0  \n",
       "LotArea          9478.5   11601.50  215245.0  \n",
       "OverallQual         6.0       7.00      10.0  \n",
       "OverallCond         5.0       6.00       9.0  \n",
       "YearBuilt        1973.0    2000.00    2010.0  \n",
       "YearRemodAdd     1994.0    2004.00    2010.0  \n",
       "MasVnrArea          0.0     166.00    1600.0  \n",
       "BsmtFinSF1        383.5     712.25    5644.0  \n",
       "BsmtFinSF2          0.0       0.00    1474.0  \n",
       "BsmtUnfSF         477.5     808.00    2336.0  \n",
       "TotalBsmtSF       991.5    1298.25    6110.0  \n",
       "1stFlrSF         1087.0    1391.25    4692.0  \n",
       "2ndFlrSF            0.0     728.00    2065.0  \n",
       "LowQualFinSF        0.0       0.00     572.0  \n",
       "GrLivArea        1464.0    1776.75    5642.0  \n",
       "BsmtFullBath        0.0       1.00       3.0  \n",
       "BsmtHalfBath        0.0       0.00       2.0  \n",
       "FullBath            2.0       2.00       3.0  \n",
       "HalfBath            0.0       1.00       2.0  \n",
       "BedroomAbvGr        3.0       3.00       8.0  \n",
       "KitchenAbvGr        1.0       1.00       3.0  \n",
       "TotRmsAbvGrd        6.0       7.00      14.0  \n",
       "Fireplaces          1.0       1.00       3.0  \n",
       "GarageYrBlt      1980.0    2002.00    2010.0  \n",
       "GarageCars          2.0       2.00       4.0  \n",
       "GarageArea        480.0     576.00    1418.0  \n",
       "WoodDeckSF          0.0     168.00     857.0  \n",
       "OpenPorchSF        25.0      68.00     547.0  \n",
       "EnclosedPorch       0.0       0.00     552.0  \n",
       "3SsnPorch           0.0       0.00     508.0  \n",
       "ScreenPorch         0.0       0.00     480.0  \n",
       "PoolArea            0.0       0.00     738.0  \n",
       "MiscVal             0.0       0.00   15500.0  \n",
       "MoSold              6.0       8.00      12.0  \n",
       "YrSold           2008.0    2009.00    2010.0  \n",
       "SalePrice      163000.0  214000.00  755000.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em uma Pipeline, podemos usar os transformadores padrão do `scikit-learn`, como o `StandardScaler` e o `OneHotEncoder`, e também podemos usar os nossos próprios transformadores personalizados. Para isso, basta criar uma classe que herda da classe `BaseEstimator` e implementar os métodos `fit()` e `transform()`. Vamos criar um transformador personalizado para realizar a transformação logarítmica, como foi realizado no notebook anterior. Vamos também criar um transformador para realizar a binarização e categorização de variáveis com alta concentração de zeros, assim como foi feito no notebook anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "        for col in self.columns:\n",
    "            X[col] = np.log1p(X[col])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "        for col in self.columns:\n",
    "            X[col] = X[col].apply(lambda x: 1 if x > 0 else 0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None, bins=10, labels=False):\n",
    "        self.columns = columns\n",
    "        self.bins = bins\n",
    "        self.labels = labels\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "        for col in self.columns:\n",
    "            X[col] = pd.cut(X[col], bins=self.bins, labels=self.labels)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `scikit-learn`, temos tanto o Pipeline quanto o Column Transformer. Os dois diferem na forma como lidam com as colunas. O Pipeline aplica as transformações em todas as colunas, enquanto o Column Transformer aplica as transformações apenas nas colunas especificadas. O interessante é que podemos utilizar o Column Transformer dentro de uma Pipeline, automatizando todo o processamento de dados, selecionando as colunas a serem transformadas com cada método. Vamos, agora, de acordo com análise exploratória realizada no notebook anterior, selecionar uma lista de variáveis para cada método de transformação. Vamos, também, criar uma lista de variáveis categóricas que serão transformadas de acordo com o método de codificação escolhido. Por fim, vamos aplicar um método de transformação de `StandardScaler` em todas as variáveis numéricas. Isso garante que todas as variáveis estejam na mesma escala, o que pode ser importante em alguns tipos de modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['Id', 'PoolArea', 'GarageArea']\n",
    "\n",
    "dataset.drop(drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['SalePrice']\n",
    "X = dataset.drop(['SalePrice'], axis=1)\n",
    "\n",
    "log_features = ['1stFlrSF', 'TotalBsmtSF', 'BsmtUnfSF', 'LotArea', 'LotFrontage']\n",
    "\n",
    "binary = ['ScreenPorch', '3SsnPorch', 'EnclosedPorch', 'LowQualFinSF']\n",
    "bins = ['OpenPorchSF', 'WoodDeckSF']\n",
    "\n",
    "df_cat = X.select_dtypes(include=['object'])\n",
    "df_num = X.select_dtypes(exclude=['object'])\n",
    "var_cat = df_cat.columns\n",
    "var_num = df_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('inputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    #('inpute_cat', SimpleImputer(strategy='most_frequent'), var_cat),\n",
    "    ('log', LogTransformer(), log_features),\n",
    "    ('cat', OneHotEncoder(drop='first'), var_cat),\n",
    "    ('binary', BinaryTransformer(), binary),\n",
    "    ('bins', BinsTransformer(bins=5), bins),\n",
    "    ('num', num_pipeline, var_num),\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X)\n",
    "X_prepared = full_pipeline.transform(X)\n",
    "small_constant = 1e-10 \n",
    "y_prepared = np.log(y + small_constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.753438</td>\n",
       "      <td>6.753438</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017598</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>0.216503</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-1.599111</td>\n",
       "      <td>0.138777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.141245</td>\n",
       "      <td>7.141245</td>\n",
       "      <td>5.652489</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107927</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>1.626195</td>\n",
       "      <td>-0.704483</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-0.489110</td>\n",
       "      <td>-0.614439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.825460</td>\n",
       "      <td>6.825460</td>\n",
       "      <td>6.075346</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934226</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>-0.070361</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>0.990891</td>\n",
       "      <td>0.138777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.869014</td>\n",
       "      <td>6.629363</td>\n",
       "      <td>6.293419</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>1.650307</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>-0.176048</td>\n",
       "      <td>4.092524</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-1.599111</td>\n",
       "      <td>-1.367655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.044033</td>\n",
       "      <td>7.044033</td>\n",
       "      <td>6.196444</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892540</td>\n",
       "      <td>1.650307</td>\n",
       "      <td>0.780197</td>\n",
       "      <td>0.563760</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>2.100892</td>\n",
       "      <td>0.138777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4    5    6    7    8    9    \\\n",
       "0  6.753438  6.753438  5.017280  9.042040  4.189655  0.0  0.0  1.0  0.0  1.0   \n",
       "1  7.141245  7.141245  5.652489  9.169623  4.394449  0.0  0.0  1.0  0.0  1.0   \n",
       "2  6.825460  6.825460  6.075346  9.328212  4.234107  0.0  0.0  1.0  0.0  1.0   \n",
       "3  6.869014  6.629363  6.293419  9.164401  4.110874  0.0  0.0  1.0  0.0  1.0   \n",
       "4  7.044033  7.044033  6.196444  9.565284  4.442651  0.0  0.0  1.0  0.0  1.0   \n",
       "\n",
       "   ...       259       260       261       262       263       264       265  \\\n",
       "0  ...  1.017598  0.311725 -0.752176  0.216503 -0.359325 -0.116339 -0.270208   \n",
       "1  ... -0.107927  0.311725  1.626195 -0.704483 -0.359325 -0.116339 -0.270208   \n",
       "2  ...  0.934226  0.311725 -0.752176 -0.070361 -0.359325 -0.116339 -0.270208   \n",
       "3  ...  0.809167  1.650307 -0.752176 -0.176048  4.092524 -0.116339 -0.270208   \n",
       "4  ...  0.892540  1.650307  0.780197  0.563760 -0.359325 -0.116339 -0.270208   \n",
       "\n",
       "        266       267       268  \n",
       "0 -0.087688 -1.599111  0.138777  \n",
       "1 -0.087688 -0.489110 -0.614439  \n",
       "2 -0.087688  0.990891  0.138777  \n",
       "3 -0.087688 -1.599111 -1.367655  \n",
       "4 -0.087688  2.100892  0.138777  \n",
       "\n",
       "[5 rows x 269 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prepared\n",
    "df = pd.DataFrame(X_prepared)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = df.isnull().sum().sort_values(ascending=False)\n",
    "cols = df_nan[df_nan > 0].index\n",
    "df[cols] = df[cols].fillna(df[cols].mean())\n",
    "X_prepared = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12.247694\n",
       "1       12.109011\n",
       "2       12.317167\n",
       "3       11.849398\n",
       "4       12.429216\n",
       "          ...    \n",
       "1455    12.072541\n",
       "1456    12.254863\n",
       "1457    12.493130\n",
       "1458    11.864462\n",
       "1459    11.901583\n",
       "Name: SalePrice, Length: 1460, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sobre o `Standard Scaler`**\n",
    "\n",
    "O Standard Scaler se trata de uma das técnicas de padronização de dados numéricos. Muitas vezes, tais dados são apresentados em escalas muito diferentes. Por exemplo, dentro do próprio dataset que estamos utilizando, há uma variável para o número de quartos, que pode variar de 1 a 10 normalmente, e outra variável para a área total da casa em Square Feet, que possui valores de grandeza maior, na casa dos milhares. Em modelos lineares, o peso atribuído a cada feature, como será visto em sequência, impede que isso seja um problema; a magnitude da feature será compensada por um peso menor ou maior, a ser atribuído pelo modelo. Contudo, em outros modelos, é importante que estejam todas as features em escalas próximas. \n",
    "O Standard Scaler irá realizar uma normalização dos dados. O cálculo que realiza é o seguinte:\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "Em que $x$ é o valor da feature, $\\mu$ é a média da feature e $\\sigma$ é o desvio padrão da feature. O resultado é que os dados serão normalizados em torno de 0, com desvio padrão 1. Acima, o dataset preparado `X_prepared` está apresentado de acordo com essas características. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. O que é Aprendizado Supervisionado?\n",
    "\n",
    "Aprendizado supervisionado é o método mais comum de Machine Learning. Quando recebemos uma base de dados para treinar um modelo supervisionado, todas as observações possuem uma resposta esperada. Ou seja, além das features com as quais desejamos treinar o modelo, temos também a variável resposta, que é o que queremos prever. No caso que estamos utilizando aqui, a variável resposta é o preço das casas, que está presente no dataset e queremos prevê-la usando um conjunto de features. Portanto, se trata de um problema de aprendizado de máquina supervisionado e, mais especificamente, de regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problemas de Regressão e Classificação\n",
    "\n",
    "A diferença entre problemas de regressão e classificação é o que desejamos prever. Em problemas de regressão, desejamos prever um valor contínuo; ou seja, um valor que pode assumir qualquer valor dentro de um intervalo. No caso do dataset que estamos utilizando, desejamos prever o preço das casas, que pode assumir qualquer valor dentro do intervalo de valores reais. Em problemas de classificação, desejamos prever um valor discreto; ou seja, um valor que pode assumir apenas um conjunto de valores finitos. Por exemplo, se desejamos prever se um e-mail é spam ou não, estamos realizando um problema de classificação. A resposta esperada é apenas \"sim\" ou \"não\". Se desejamos prever se uma pessoa é boa ou má pagadora de crédito, estamos realizando um problema de classificação. A resposta esperada é apenas \"sim\" ou \"não\". Existem problemas de classificação binários, com apenas duas respostas possíveis, e problemas multiclasse, em que há mais possibilidades de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regressão e os Principais Algoritmos\n",
    "\n",
    "Existem vários modelos de regressão, para realizar predições com valores contínuos. Aqui, vamos tratar dos principais e mais utilizados, tanto em competições de Machine Learning quanto em aplicações práticas.\n",
    "\n",
    "### 4.1. Regressão Linear\n",
    "\n",
    "Uma regressão linear é o modelo mais básico, que vale a pena ser testado em qualquer problema de regressão. A regressão linear é um modelo linear, ou seja, que assume que a relação entre as variáveis é linear. A equação de uma regressão linear múltipla é a seguinte:\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n\n",
    "$$\n",
    "Com os valores de $\\beta$ sendo os coeficientes do modelo, ou seja, os pesos, e $\\beta_0$ sendo o termo de viés. A regressão linear é um modelo simples, que não possui muitos parâmetros para serem otimizados. Por isso, é um modelo rápido de ser treinado e que pode ser utilizado como baseline para comparação com outros modelos. Porém, muitas vezes, pode apresentar uma solução suficientemente boa para o problema.\n",
    "\n",
    "Em todo problema de Machine Learning, as amostras de entrada serão caracterizadas como um vetor de features, que pode ser caracterizado como:\n",
    "$$\n",
    "\\mathbf{X} = [x_1, x_2, ..., x_n]\n",
    "$$\n",
    "E um modelo de machine larning será uma função que permite estimar a saída para esse vetor de entrada. Essa saída vai depender dos parâmetros do modelo que serão treinados com os dados de treino. Ou seja:\n",
    "$$\n",
    "\\hat{y} = f(\\mathbf{X}, \\theta)\n",
    "$$\n",
    "Com $\\theta$ sendo o vetor de parâmetros do modelo. No caso da regressão linear, os parâmetros são os coeficientes $\\beta$ e o termo de viés $\\beta_0$. Para termos de notação, $\\hat{y}$ é a saída estimada pelo modelo e $y$ é a saída real, que está presente no dataset. O objetivo do modelo é minimizar o erro entre a saída estimada e a saída real. Para isso, é utilizado um método de otimização, que pode ser o método dos mínimos quadrados, por exemplo. O método dos mínimos quadrados consiste em minimizar a soma dos quadrados dos erros, ou seja:\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Isso quer dizer que, basicamente, o modelo irá tentar minimizar a soma dos quadrados dos erros, constituídos na diferença entre a saída real e a estimada. \n",
    "\n",
    "A regressão linear será treinada podendo utilizar tanto conceitos de álgebra linear, quanto conceitos de matemática multivariada.\n",
    "\n",
    "**Gradiente Descendente:** o gradiente descendente irá atualizar os parâmetros de acordo com a seguinte equação:\n",
    "$$\n",
    "\\theta_{i+1} = \\theta_i - \\alpha \\frac{\\partial}{\\partial \\theta_i} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Ou seja, para cada etapa do modelo, o algoritmo irá derivar a função de erro e irá atualizar os parâmetros de acordo com a direção do gradiente. O parâmetro $\\alpha$ é o learning rate, que controla o tamanho do passo que o algoritmo irá dar em cada etapa. Se o learning rate for muito pequeno, o algoritmo irá demorar muito para convergir. Se o learning rate for muito grande, o algoritmo pode não convergir. O gradiente descendente é um algoritmo iterativo, que irá atualizar os parâmetros até que a função de erro convirja para um mínimo local. O gradiente descendente é um algoritmo muito utilizado para treinar modelos de regressão linear, mas também pode ser utilizado para treinar outros modelos de regressão e classificação.\n",
    "\n",
    "**Equação Normal:** a equação normal é uma equação que permite encontrar os parâmetros do modelo de regressão linear sem a necessidade de utilizar um algoritmo iterativo. A equação normal é a seguinte:\n",
    "$$\n",
    "\\theta = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n",
    "$$\n",
    "Em que $\\mathbf{X}$ é a matriz de features, $\\mathbf{y}$ é o vetor de saídas e $\\theta$ é o vetor de parâmetros do modelo. A equação normal é uma equação matemática que permite encontrar os parâmetros do modelo de regressão linear de forma direta. Porém, ela só pode ser utilizada se a matriz $\\mathbf{X}^T \\mathbf{X}$ for inversível. Caso contrário, o algoritmo irá apresentar um erro. Além disso, a equação normal não é um algoritmo iterativo, ou seja, não é possível atualizar os parâmetros do modelo de forma incremental. Porém, ela é muito mais rápida que o gradiente descendente, pois não é necessário realizar várias iterações para encontrar os parâmetros do modelo.\n",
    "\n",
    "Para explicar com precisão como um modelo de regressão linear é treinado, precisamos de muita álgebra linear. O importante é saber que o modelo de regressão linear é um modelo simples, que pode ser treinado de forma rápida e que pode ser utilizado como baseline para comparação com outros modelos. Porém, ele assume que a relação entre as variáveis é linear, o que pode não ser verdade em muitos casos. Também pode ser interessante que a variável resposta se aproxime de uma distribuição normal, o que pode não ser verdade em muitos casos. Porém, é um modelo que vale a pena ser testado em qualquer problema de regressão. Para mais informações sobre o modelo de regressão linear e para tentar realizar uma implementação do modelo com força bruta, recomendo acessar a parte 4 do módulo de Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo para realizar o modelo é separar em variáveis de entrada e variável de saída. Para isso, vamos utilizar o dataset preparado `X_prepared` e a variável resposta `y`. Vamos, também, separar os dados em treino e teste, para que possamos avaliar o modelo. Vamos utilizar a função `train_test_split` do `scikit-learn` para realizar essa separação. Vamos utilizar 20% dos dados para teste e 80% para treino. Vamos, também, utilizar o parâmetro `random_state` para garantir que os dados serão separados da mesma forma em todas as execuções do notebook. É importante realizarmos essa separação para que possamos avaliar o modelo em dados que não foram utilizados para treiná-lo. Caso contrário, o modelo pode apresentar um desempenho muito bom nos dados de treino, mas um desempenho ruim nos dados de teste. Isso é chamado de overfitting, que é quando o modelo se ajusta muito bem aos dados de treino, mas não consegue generalizar para dados novos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_prepared, y_prepared, test_size=0.2, random_state=42)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.19858353e+01,  1.27412781e+01,  1.15330261e+01,  1.20711624e+01,\n",
       "        1.26526371e+01,  1.12373718e+01,  1.24404610e+01,  1.19570984e+01,\n",
       "        1.12790661e+01,  1.18716133e+01,  1.19368168e+01,  1.16082035e+01,\n",
       "        1.11020821e+01,  1.22373718e+01,  1.20234509e+01,  1.18173962e+01,\n",
       "        1.21145153e+01,  1.17695446e+01,  1.16362438e+01,  1.22614880e+01,\n",
       "        1.18232376e+01,  1.22327152e+01,  1.20193363e+01,  1.18360046e+01,\n",
       "        1.21799808e+01,  1.19338692e+01,  1.21418591e+01,  1.15493835e+01,\n",
       "        1.20967110e+01,  1.22273083e+01,  1.21181595e+01,  1.25202950e+01,\n",
       "        1.23249645e+01,  1.16838692e+01,  1.24665661e+01,  1.19409493e+01,\n",
       "        1.18711429e+01,  1.22253552e+01,  1.26674759e+01,  1.16362618e+01,\n",
       "        1.17404740e+01,  1.22543396e+01,  1.16418591e+01,  1.27141605e+01,\n",
       "        1.17419567e+01,  1.17204724e+01,  1.15810501e+01,  1.18144665e+01,\n",
       "        1.30168949e+01,  1.18479138e+01,  1.17136364e+01,  1.22698246e+01,\n",
       "        1.15854805e+01,  1.23911446e+01,  1.20444649e+01,  1.23769486e+01,\n",
       "        1.22258793e+01,  1.19165352e+01,  1.17454284e+01,  1.15830749e+01,\n",
       "        1.13579414e+01,  1.19619812e+01,  1.26359997e+01,  1.24546211e+01,\n",
       "        1.26403942e+01,  1.20505505e+01,  1.16584606e+01,  1.27134102e+01,\n",
       "        1.18872204e+01,  1.20495739e+01,  1.16848637e+01,  1.17807930e+01,\n",
       "        1.16308907e+01,  1.12871048e+01,  1.31221374e+01,  1.20537422e+01,\n",
       "        1.26425736e+01,  1.26860664e+01,  1.19540970e+01,  1.17329414e+01,\n",
       "        1.16125980e+01,  3.51809056e+09,  1.16499336e+01,  1.16418949e+01,\n",
       "        1.19570267e+01,  1.18645512e+01,  1.25175736e+01,  1.21386673e+01,\n",
       "        1.18398392e+01,  1.21638317e+01,  1.18484020e+01,  1.18503552e+01,\n",
       "        1.18078747e+01,  1.25896130e+01,  1.16455749e+01,  1.21308548e+01,\n",
       "        1.21458012e+01,  1.19716751e+01,  1.22353470e+01,  1.24265629e+01,\n",
       "        1.20056286e+01,  1.22368477e+01,  1.25388317e+01,  1.18200817e+01,\n",
       "        1.22302380e+01,  1.20229984e+01,  1.19895512e+01,  1.25234330e+01,\n",
       "        1.18945625e+01,  1.21535778e+01,  1.07795902e+01,  1.16854740e+01,\n",
       "        1.19148620e+01,  1.18410778e+01,  1.21967907e+01,  1.16314148e+01,\n",
       "        1.16055000e+01,  1.16540661e+01,  1.16162781e+01,  3.14319026e+11,\n",
       "        1.18708630e+01,  1.18432930e+01,  1.20544567e+01,  1.21658028e+01,\n",
       "        1.22200199e+01,  1.18486283e+01,  1.23235355e+01,  1.16636055e+01,\n",
       "        1.19604805e+01,  1.20747025e+01,  1.21299141e+01,  1.27734330e+01,\n",
       "        1.21760746e+01,  1.16743656e+01,  1.06445267e+01,  1.28059574e+01,\n",
       "        1.27886055e+01,  1.17739571e+01,  1.23339798e+01,  1.36071911e+01,\n",
       "        1.28372074e+01,  1.17917614e+01,  1.20244812e+01,  1.20161446e+01,\n",
       "        1.18452103e+01,  1.17270462e+01,  1.23349564e+01,  1.21165043e+01,\n",
       "        1.17458988e+01,  1.12514961e+01,  1.17470658e+01,  1.18046830e+01,\n",
       "        1.24626599e+01,  1.19878601e+01,  1.13190873e+01,  1.16462894e+01,\n",
       "        1.18120430e+01,  1.18305619e+01,  1.13884411e+01,  1.17339359e+01,\n",
       "        1.21914375e+01,  1.17205261e+01,  1.26518868e+01,  1.18975281e+01,\n",
       "        1.16294258e+01,  1.16833630e+01,  1.24348278e+01,  1.27048474e+01,\n",
       "        1.30937455e+01,  1.22798523e+01,  1.28203080e+01,  1.15041638e+01,\n",
       "        1.16977494e+01,  1.20659493e+01,  1.26403942e+01,  1.16440743e+01,\n",
       "        1.15913757e+01,  1.22819958e+01,  1.17211869e+01,  1.20591491e+01,\n",
       "        1.22920235e+01,  1.11211609e+01,  1.17827103e+01,  1.18254887e+01,\n",
       "        1.24728958e+01,  1.19707702e+01,  1.25044258e+01,  1.23447220e+01,\n",
       "        1.22206986e+01,  1.13337536e+01,  1.16960583e+01,  1.16193802e+01,\n",
       "        1.19319340e+01,  1.21703194e+01,  1.21531254e+01,  1.21098587e+01,\n",
       "        1.22705033e+01,  1.10913399e+01,  1.21915775e+01,  1.18035160e+01,\n",
       "        1.23515580e+01,  1.21675118e+01,  1.15110355e+01,  1.26850899e+01,\n",
       "        1.21911755e+01,  1.17783158e+01,  1.23276859e+01,  1.18759037e+01,\n",
       "        1.18729203e+01,  1.15923164e+01,  1.23635388e+01,  1.18943005e+01,\n",
       "        1.16113952e+01,  1.20686527e+01, -8.80075479e+10,  1.24434265e+01,\n",
       "        1.22932263e+01,  1.18242142e+01,  1.16074173e+01,  1.17512699e+01,\n",
       "        1.17636673e+01,  1.23015629e+01,  1.23105423e+01,  1.14299808e+01,\n",
       "        1.22776371e+01,  1.19260746e+01,  1.10391296e+01,  1.15940075e+01,\n",
       "        1.20698555e+01,  1.11636413e+01,  1.14561218e+01,  1.20058548e+01,\n",
       "        1.15737259e+01,  1.18037601e+01,  1.22490189e+01,  1.18786755e+01,\n",
       "        1.21884899e+01,  1.19668640e+01,  1.24072399e+01,  1.17046570e+01,\n",
       "        1.16260437e+01,  1.24700378e+01,  1.23886169e+01,  1.32070267e+01,\n",
       "        1.21081856e+01,  1.17314461e+01,  1.19143379e+01,  1.20806839e+01,\n",
       "        1.17949352e+01,  1.14223946e+01,  1.20610306e+01,  1.19558239e+01,\n",
       "        1.18681953e+01,  1.14167614e+01,  1.17939408e+01,  1.18391784e+01,\n",
       "        1.16755863e+01,  1.16741215e+01,  1.19755814e+01,  1.24699841e+01,\n",
       "        1.25622692e+01,  1.20998490e+01,  1.18057312e+01,  1.23870121e+01,\n",
       "        1.27146130e+01,  1.24287422e+01,  1.19760697e+01,  1.18118168e+01,\n",
       "        1.15730472e+01,  1.20772156e+01,  1.29804642e+01,  1.23442696e+01,\n",
       "        1.23821293e+01,  1.12803406e+01,  1.14235974e+01,  1.18411137e+01,\n",
       "        1.18623001e+01,  1.25915661e+01,  1.24026371e+01,  1.18596504e+01,\n",
       "       -1.78847428e+10,  1.12597611e+01,  1.22187455e+01,  1.15959965e+01,\n",
       "        1.26204105e+01,  1.20813480e+01,  1.22729984e+01,  1.18076306e+01,\n",
       "        1.25168949e+01,  1.21098946e+01,  1.16409183e+01,  1.17170902e+01])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como realizamos uma transformação logarítmica na variável resposta, nosso vetor de previsões $\\hat{y}$ irá apresentar a previsão do logaritmo do preço das casas. Para obtermos a previsão do preço das casas, precisamos aplicar a função exponencial no vetor de previsões.\n",
    "\n",
    "Vamos avaliar o modelo de regressão linear. Para isso, vamos usar o RMSE, que é a raiz do erro quadrático médio. O RMSE é uma métrica de avaliação de modelos de regressão que mede a diferença entre os valores reais e os valores previstos pelo modelo. O RMSE é calculado da seguinte forma:\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "Como estão em escala logarítmica, vamos calcular o RMSE em escala logarítmica e depois aplicar a função exponencial para obtermos o RMSE em escala original. Vamos também calcular o coeficiente de determinação $R^2$, que é uma métrica que mede a proporção da variância da variável resposta que é explicada pelo modelo. O $R^2$ é calculado da seguinte forma:\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "$$\n",
    "Em que $\\bar{y}$ é a média da variável resposta. O $R^2$ é uma métrica que varia de 0 a 1. Quanto mais próximo de 1, melhor o modelo. Quanto mais próximo de 0, pior o modelo. O $R^2$ é uma métrica que pode ser utilizada para comparar modelos. Porém, não é uma métrica que pode ser utilizada para avaliar a qualidade de um modelo. Isso porque o $R^2$ sempre irá aumentar quando adicionamos mais variáveis ao modelo, mesmo que essas variáveis não sejam relevantes para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  34039.85543761642\n",
      "R2:  0.8489357913972281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_lr = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_lr)\n",
    "print('R2: ', r2_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço médio das casas: 180921.20.\n",
      "RMSE representa aproximadamente 18.81% do preço médio de casas.\n"
     ]
    }
   ],
   "source": [
    "print(f'Preço médio das casas: {y.mean():.2f}.')\n",
    "print(f'RMSE representa aproximadamente {rmse_lr/y.mean()*100:.2f}% do preço médio de casas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, temos um RMSE de aproximadamente 35000 e um R2 score de aproximadamente 0.85. Como dito anteriormente, o R2 score não é utilizado para avaliar a qualidade do modelo, mas sim o quanto do resultado é explicado pelo modelo, sendo muito mais útil para realizar comparações entre modelos. O RMSE já consegue avaliar a qualidade do modelo, mas é uma métrica que depende da escala da variável resposta. Vamos comparar o resultado obtido com a média do preço das casas, que é de aproximadamente 180000. O RMSE representa aproximadamente 20% da média do preço das casas. Para casas com preço maior, isso pode ser um bom resultado, mas para casas com preço menor pode representar um erro de mais de 50%. Vamos utilizar outros modelos para compará-los."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Regressão de Árvore de Decisão e Floresta Aleatória\n",
    "\n",
    "Uma árvore de decisão é exatamente o que o nome sugere: uma árvore que, a partir da raiz, a cada nó, toma uma decisão até chegar no melhor valor. Mais para a frente vamos ver um exemplo de um regressor, e plotar a árvore. Por enquanto, vamos entender como funciona o algoritmo.\n",
    "\n",
    "A árvore de decisão começa em um nó raiz, contendo todo o conjunto de dados. Para cada nó, o algoritmo irá escolher uma feature que melhor separa os dados, com base em algum critério. O critério mais comum para problemas de classificação é a impureza de Gini, e para problemas de regressão, o erro quadrático médio. O algoritmo tomará uma decisão e dividirã a amostra nos dois nós filhos. Cada nó irá representar uma regra de decisão. Isso ficará mais claro quando plotarmos a árvore visualmente. O algoritmo irá repetir esse processo até que não seja mais possível dividir os dados, ou até chegar na profundidade máxima (critério de parada).\n",
    "\n",
    "O algoritmo de Random Forest (Floresta Aleatória) funciona de forma semelhante, porém se trata de um modelo de ensemble: vários modelos de árvore de decisão são utilizados sequencialmente para tomar uma decisão. Cada árvore é construída de forma independente usando parte aleatória da amostra de treino, e cada árvore é treinada de forma independente, seguindo o mesmo algoritmo descrito anteriormente. Em problemas de classificação, a decisão final será com base em uma votação entre todas as árvores, com a classe mais votada sendo o retorno do algoritmo. Em problemas de regressão, o resultado final é a média de todas as árvores da floresta. \n",
    "\n",
    "A Floresta Aleatória é um dos algoritmos mais utilizados em problemas de classificação, mas também é importante em problemas de regressão. É um algoritmo que apresenta um bom desempenho na maioria dos problemas, com vantagens frente às Árvores de Decisão individuais por reduzir o Overfitting (conceito que trataremos mais adiante). Caso queira saber mais sobre os modelos de árvore, consulte nossa bibliografia complementar!\n",
    "\n",
    "Para plotar uma árvore de decisão básica com os dados que temos, acesse o notebook `plot_tree.ipynb`, disponível na mesma pasta desse notebook. Aqui, vamos partir para o modelo e avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_prepared, y_prepared, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  43530.37832010858\n",
      "R2:  0.7529578553104747\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_dt = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_dt)\n",
    "print('R2: ', r2_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguindo a lógica explicada anteriormente, o modelo de árvore de decisão chegou a um resultado com RMSE de aproximadamente 43500, e R2 Score de aproximadamente 0.75. Em comparação com o modelo linear, a árvore de decisão apresentou um desempenho pior, porém rodou de forma muito mais eficiente. Vamos, agora, testar os resultados para o modelo de Floresta Aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# o hiperparâmetro n_estimators define o número de árvores na floresta\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  29085.41396725085\n",
      "R2:  0.8897098659436827\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_rf = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_rf)\n",
    "print('R2: ', r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço médio das casas: 180921.20.\n",
      "RMSE representa aproximadamente 16.08% do preço médio de casas.\n"
     ]
    }
   ],
   "source": [
    "print('Preço médio das casas: {:.2f}.'.format(y.mean()))\n",
    "print('RMSE representa aproximadamente {:.2f}% do preço médio de casas.'.format(rmse_rf/y.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de Floresta Aleatória foi o que, até agora, apresentou o melhor desempenho, porém também foi o que mais demorou para rodar. Apresentou um RMSE de menos de 30000 e R2 Score de 0.89. O erro representa cerca de 16% do preço médio das casas, o que é um desempenho relevante. Contudo, com um trade-off de tempo de processamento.\n",
    "\n",
    "Vamos ver mais alternativas de modelos de regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Regressão de KNN\n",
    "\n",
    "O algoritmo K-Nearest Neighbors (K-Vizinhos mais próximos) ou, abreviado, KNN, estima os valores alvo com base na média dos valores alvo das $K$ instâncias mais próximas no espaço de características. Simples assim.\n",
    "\n",
    "O algoritmo irá calcular a distância entre as instâncias de treino e a instância de teste, e irá selecionar as $K$ instâncias mais próximas. A distância pode ser calculada de várias formas, sendo a distância euclidiana a mais comum, mas também podendo utilizar a distância de Manhattan, por exemplo. É um algoritmo muito simples, que pode ser muito útil em alguns casos, mas com muitas features e muitos vizinhos pode apresentar um processamento muito lento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_prepared, y_prepared, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "knn_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  38111.9946563933\n",
      "R2:  0.8106307218944703\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_knn = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_knn = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_knn)\n",
    "print('R2: ', r2_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É um modelo muito simples e que possui várias aplicações, porém não possui, nesse caso, um desempenho muito bom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Regressão de Gradiente\n",
    "\n",
    "Algoritmos de Gradient Boosting são modelos de Ensemble, como as florestas aleatórias, que utilizam vários modelos fracos para formar um modelo forte, basicamente. O Gradient Boosting funciona de maneira iterativa, ajustando um novo modelo fraco, geralmente árvores de decisão pequenas, para corrigir os erros de modelos anteriores. O algoritmo irá ajustar um modelo inicial, e irá calcular os erros residuais. O próximo modelo irá tentar corrigir esses erros residuais, e assim por diante. O algoritmo irá parar quando atingir um número máximo de iterações, ou quando o erro não puder ser mais reduzido.\n",
    "\n",
    "O algoritmo XGBoost (Extreme Gradient Boosting) implementa métodos de regularização no processo de otimização, tornando o modelo mais robusto contra overfitting. Em resumo, regularização é um processo dentro do modelo que penaliza modelos com muitos parâmetros, evitando o sobreajuste (vamos tratar mais disso mais para a frente). O XGBoost é um dos algoritmos mais utilizados em competições de Machine Learning, e é um dos algoritmos mais poderosos para problemas de regressão e classificação.\n",
    "\n",
    "O algoritmo LoghtGBM é outro exemplo de algoritmo de gradiente, que utiliza uma técnica chamada \"Gradient-based One-Side Sampling\" (GOSS). No geral, não é muito importante entendermos como eesa técnica funciona, mas é importante saber que ela torna o algoritmo mais rápido e mais eficiente. \n",
    "\n",
    "Em resumo, os três algoritmos são muito importantes e é sempre relevante testá-los em problemas de regressão e classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_prepared, y_prepared, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=1.0, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=1.0, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, random_state=42)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt_reg = GradientBoostingRegressor(max_depth=3, n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "gbrt_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbrt_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  32516.53488661677\n",
      "R2:  0.8621538364246036\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_gbrt = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_gbrt = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_gbrt)\n",
    "print('R2: ', r2_gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando XGBoost\n",
    "!pip install xgboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=8,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=8,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=8,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import multiprocessing\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, \n",
    "                           n_jobs=multiprocessing.cpu_count(),\n",
    "                           n_estimators=500, \n",
    "                           max_depth=3, \n",
    "                           learning_rate=0.1)\n",
    "\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  25873.047896095453\n",
      "R2:  0.9127267094838281\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_xgb = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_xgb)\n",
    "print('R2: ', r2_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando LightGBM\n",
    "!pip install lightgbm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4054\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score 12.030652\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_jobs=8, objective=&#x27;regression&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(n_jobs=8, objective=&#x27;regression&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(n_jobs=8, objective='regression', random_state=42)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_reg = lgb.LGBMRegressor(objective='regression', random_state=42,\n",
    "                            n_jobs=multiprocessing.cpu_count())\n",
    "\n",
    "lgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  29264.9326114545\n",
      "R2:  0.8883442167100417\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_lgb = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_lgb)\n",
    "print('R2: ', r2_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui temos alguns dos modelos mais poderosos que testamos até agora, e por isso são os modelos mais amplamente utilizados em problemas e competições de Machine Learning. Quando os problemas não incluem questões complexas que só seriam resolvidas com Deep Learning, provavelmente são os modelos que se saem melhor. É sempre válido testá-los em problemas de regressão e classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Support Vector Machine\n",
    "\n",
    "SVMs normalmente são usadas para problemas de classificação, mas que também podem ser adaptadas para problemas de regressão. Nesse caso, é chamado de SVR (Support Vector Regression). O algoritmo irá tentar encontrar a função que melhor se ajusta aos dados. Diferente de modelos lineares, a SVR funciona muito bem para dados que não seguem distribuições lineares, que seguem distribuições complexas. Ou seja, funciona bem quando existe uma relação complexa e não linear entre as variáveis independentes e a dependente. \n",
    "\n",
    "Começamos o modelo selecionando um Kernel (uma função de mapeamento) que será responsável por mapear os dados e treinar o modelo. O Kernel mais comum é o RBF (Radial Basis Function), mas também podemos utilizar o Linear, o Polynomial, o Sigmoid, entre outros. É interessante testar, de acordo com a distribuição dos seus dados. O SVR vai realizar o treinamento de modo a encontrar a função que minimiza a diferença entre as previsões e os valores reais.\n",
    "\n",
    "O SVR possui um hiperparâmetro de regularização: `C`. Como já visto anteriormente, a regularização é importante para evitar o sobreajuste no modelo, e o parâmetro `C`, basicamente, representa o ajuste da penalização por erros de treinamento. Vamos tratar melhor sobre isso mais para a frente, nos tópicos de regularização.\n",
    "\n",
    "Vamos testar o modelo de SVR o Kernel mais utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_prepared, y_prepared, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(C=100000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=100000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(C=100000)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_reg = SVR(kernel='rbf', C=100000)\n",
    "\n",
    "svr_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  27458.688715756904\n",
      "R2:  0.9017017574451587\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig, y_test_orig = np.exp(y_pred), np.exp(y_test)\n",
    "y_pred_orig[y_pred_orig == np.inf] = np.nan\n",
    "y_pred_orig = np.nan_to_num(y_pred_orig)\n",
    "y_test_orig[y_test_orig == np.inf] = np.nan\n",
    "y_test_orig = np.nan_to_num(y_test_orig)\n",
    "\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "r2_svr = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print('RMSE: ', rmse_svr)\n",
    "print('R2: ', r2_svr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ai-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
